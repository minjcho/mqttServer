#!/usr/bin/env python3
"""
ì¹´í”„ì¹´ ë°ì´í„° í™•ì¸ ë„êµ¬
Kafka Data Checker Tool
"""

import json
import time
from kafka import KafkaConsumer, KafkaProducer
from kafka.admin import KafkaAdminClient, NewTopic
import redis

class KafkaDataChecker:
    def __init__(self):
        self.bootstrap_servers = ['localhost:9092']
        self.redis_host = 'localhost'
        self.redis_port = 6379
        
    def check_kafka_connection(self):
        """ì¹´í”„ì¹´ ì—°ê²° í™•ì¸"""
        try:
            admin_client = KafkaAdminClient(
                bootstrap_servers=self.bootstrap_servers,
                request_timeout_ms=5000
            )
            metadata = admin_client.describe_cluster()
            print("âœ… ì¹´í”„ì¹´ ì—°ê²° ì„±ê³µ")
            return True
        except Exception as e:
            print(f"âŒ ì¹´í”„ì¹´ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def list_topics(self):
        """ëª¨ë“  í† í”½ ëª©ë¡ í™•ì¸"""
        try:
            admin_client = KafkaAdminClient(bootstrap_servers=self.bootstrap_servers)
            topics = admin_client.list_topics()
            print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ í† í”½: {list(topics)}")
            return list(topics)
        except Exception as e:
            print(f"âŒ í† í”½ ëª©ë¡ í™•ì¸ ì‹¤íŒ¨: {e}")
            return []
    
    def check_topic_details(self, topic_name):
        """íŠ¹ì • í† í”½ì˜ ìƒì„¸ ì •ë³´ í™•ì¸"""
        try:
            consumer = KafkaConsumer(
                bootstrap_servers=self.bootstrap_servers,
                consumer_timeout_ms=5000
            )
            
            partitions = consumer.partitions_for_topic(topic_name)
            if partitions:
                print(f"ğŸ“Š í† í”½ '{topic_name}' íŒŒí‹°ì…˜: {list(partitions)}")
                
                # ê° íŒŒí‹°ì…˜ì˜ ì˜¤í”„ì…‹ ì •ë³´ í™•ì¸
                from kafka import TopicPartition
                topic_partitions = [TopicPartition(topic_name, p) for p in partitions]
                
                # ì‹œì‘ ì˜¤í”„ì…‹
                beginning_offsets = consumer.beginning_offsets(topic_partitions)
                # ë ì˜¤í”„ì…‹
                end_offsets = consumer.end_offsets(topic_partitions)
                
                print(f"ğŸ“ˆ ì˜¤í”„ì…‹ ì •ë³´:")
                for tp in topic_partitions:
                    start = beginning_offsets.get(tp, 0)
                    end = end_offsets.get(tp, 0)
                    message_count = end - start
                    print(f"  íŒŒí‹°ì…˜ {tp.partition}: ì‹œì‘={start}, ë={end}, ë©”ì‹œì§€ ìˆ˜={message_count}")
            else:
                print(f"âš ï¸ í† í”½ '{topic_name}'ì— íŒŒí‹°ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
                
            consumer.close()
        except Exception as e:
            print(f"âŒ í† í”½ ìƒì„¸ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    def consume_messages(self, topic_name, max_messages=10):
        """ë©”ì‹œì§€ ì†Œë¹„í•˜ì—¬ ë‚´ìš© í™•ì¸"""
        print(f"ğŸ” í† í”½ '{topic_name}'ì—ì„œ ìµœëŒ€ {max_messages}ê°œ ë©”ì‹œì§€ í™•ì¸ ì¤‘...")
        
        try:
            consumer = KafkaConsumer(
                topic_name,
                bootstrap_servers=self.bootstrap_servers,
                auto_offset_reset='earliest',
                group_id=f'checker-group-{int(time.time())}',
                value_deserializer=lambda x: x.decode('utf-8') if x else None,
                consumer_timeout_ms=10000
            )
            
            message_count = 0
            for message in consumer:
                message_count += 1
                print(f"\nğŸ“¨ ë©”ì‹œì§€ #{message_count}:")
                print(f"  í† í”½: {message.topic}")
                print(f"  íŒŒí‹°ì…˜: {message.partition}")
                print(f"  ì˜¤í”„ì…‹: {message.offset}")
                print(f"  í‚¤: {message.key}")
                print(f"  ê°’: {message.value}")
                print(f"  íƒ€ì„ìŠ¤íƒ¬í”„: {message.timestamp}")
                print("-" * 50)
                
                if message_count >= max_messages:
                    break
            
            if message_count == 0:
                print("ğŸ“­ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            else:
                print(f"âœ… ì´ {message_count}ê°œ ë©”ì‹œì§€ í™•ì¸ ì™„ë£Œ")
                
            consumer.close()
            
        except Exception as e:
            print(f"âŒ ë©”ì‹œì§€ ì†Œë¹„ ì‹¤íŒ¨: {e}")
    
    def send_test_message(self, topic_name, test_message):
        """í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡"""
        try:
            producer = KafkaProducer(
                bootstrap_servers=self.bootstrap_servers,
                value_serializer=lambda x: x.encode('utf-8')
            )
            
            future = producer.send(topic_name, test_message)
            result = future.get(timeout=10)
            
            print(f"âœ… í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ:")
            print(f"  í† í”½: {result.topic}")
            print(f"  íŒŒí‹°ì…˜: {result.partition}")
            print(f"  ì˜¤í”„ì…‹: {result.offset}")
            
            producer.close()
            return True
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False
    
    def check_redis_data(self):
        """Redisì— ì €ì¥ëœ ë°ì´í„° í™•ì¸"""
        try:
            redis_client = redis.Redis(
                host=self.redis_host,
                port=self.redis_port,
                db=0,
                decode_responses=True
            )
            
            redis_client.ping()
            print("âœ… Redis ì—°ê²° ì„±ê³µ")
            
            # ëª¨ë“  í‚¤ í™•ì¸
            keys = redis_client.keys("*")
            print(f"ğŸ—‚ï¸ Redis í‚¤ ê°œìˆ˜: {len(keys)}")
            
            if keys:
                print("ğŸ“‹ Redis í‚¤ ëª©ë¡:")
                for key in keys[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                    key_type = redis_client.type(key)
                    print(f"  {key} ({key_type})")
                    
                    # ì¼ë¶€ ë°ì´í„° ë‚´ìš© í‘œì‹œ
                    if key_type == 'string':
                        value = redis_client.get(key)
                        print(f"    ê°’: {value[:100]}...")
                    elif key_type == 'hash':
                        hash_data = redis_client.hgetall(key)
                        print(f"    í•´ì‹œ í•„ë“œ ìˆ˜: {len(hash_data)}")
                        
                if len(keys) > 10:
                    print(f"  ... ë° {len(keys) - 10}ê°œ ë”")
            else:
                print("ğŸ“­ Redisì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"âŒ Redis í™•ì¸ ì‹¤íŒ¨: {e}")
    
    def run_comprehensive_check(self):
        """ì¢…í•© ë°ì´í„° í™•ì¸"""
        print("ğŸš€ ì¹´í”„ì¹´ ë°ì´í„° ì¢…í•© í™•ì¸ ì‹œì‘")
        print("=" * 60)
        
        # 1. ì¹´í”„ì¹´ ì—°ê²° í™•ì¸
        print("\n1ï¸âƒ£ ì¹´í”„ì¹´ ì—°ê²° í™•ì¸")
        if not self.check_kafka_connection():
            return
        
        # 2. í† í”½ ëª©ë¡ í™•ì¸
        print("\n2ï¸âƒ£ í† í”½ ëª©ë¡ í™•ì¸")
        topics = self.list_topics()
        
        # 3. ê° í† í”½ ìƒì„¸ ì •ë³´ í™•ì¸
        print("\n3ï¸âƒ£ í† í”½ ìƒì„¸ ì •ë³´ í™•ì¸")
        for topic in topics:
            print(f"\n--- í† í”½: {topic} ---")
            self.check_topic_details(topic)
        
        # 4. ë©”ì‹œì§€ ë‚´ìš© í™•ì¸
        print("\n4ï¸âƒ£ ë©”ì‹œì§€ ë‚´ìš© í™•ì¸")
        for topic in topics:
            print(f"\n--- í† í”½ '{topic}' ë©”ì‹œì§€ í™•ì¸ ---")
            self.consume_messages(topic, max_messages=5)
        
        # 5. Redis ë°ì´í„° í™•ì¸
        print("\n5ï¸âƒ£ Redis ë°ì´í„° í™•ì¸")
        self.check_redis_data()
        
        print("\n" + "=" * 60)
        print("âœ… ì¢…í•© í™•ì¸ ì™„ë£Œ")

def main():
    checker = KafkaDataChecker()
    
    import sys
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "topics":
            checker.list_topics()
        elif command == "messages":
            topic = sys.argv[2] if len(sys.argv) > 2 else "mqtt-messages"
            max_msgs = int(sys.argv[3]) if len(sys.argv) > 3 else 10
            checker.consume_messages(topic, max_msgs)
        elif command == "redis":
            checker.check_redis_data()
        elif command == "test":
            topic = sys.argv[2] if len(sys.argv) > 2 else "mqtt-messages"
            message = sys.argv[3] if len(sys.argv) > 3 else f"í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ - {time.time()}"
            checker.send_test_message(topic, message)
        elif command == "check":
            topic = sys.argv[2] if len(sys.argv) > 2 else "mqtt-messages"
            checker.check_topic_details(topic)
        else:
            print("ì‚¬ìš©ë²•:")
            print("  python kafka_data_checker.py topics          # í† í”½ ëª©ë¡")
            print("  python kafka_data_checker.py messages [í† í”½] [ê°œìˆ˜]  # ë©”ì‹œì§€ í™•ì¸")
            print("  python kafka_data_checker.py redis           # Redis ë°ì´í„°")
            print("  python kafka_data_checker.py test [í† í”½] [ë©”ì‹œì§€]    # í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡")
            print("  python kafka_data_checker.py check [í† í”½]    # í† í”½ ìƒì„¸ ì •ë³´")
    else:
        # ì¸ìˆ˜ê°€ ì—†ìœ¼ë©´ ì¢…í•© í™•ì¸ ì‹¤í–‰
        checker.run_comprehensive_check()

if __name__ == "__main__":
    main()