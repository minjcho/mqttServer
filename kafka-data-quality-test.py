#!/usr/bin/env python3

"""
ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ ê´€ì ì˜ Kafka í’ˆì§ˆ ê²€ì¦
- ë°ì´í„° ë¬´ê²°ì„±, ì¤‘ë³µ, ìˆœì„œ, ìŠ¤í‚¤ë§ˆ ê²€ì¦
"""

import json
import time
import hashlib
from datetime import datetime, timedelta
from collections import defaultdict
from kafka import KafkaProducer, KafkaConsumer
from kafka.structs import TopicPartition
import pandas as pd
import numpy as np

class DataQualityTest:
    def __init__(self, bootstrap_servers='localhost:9092'):
        self.bootstrap_servers = bootstrap_servers
        self.test_results = {
            'duplicates': [],
            'out_of_order': [],
            'data_loss': [],
            'schema_violations': [],
            'latency_issues': []
        }
        
    def test_exactly_once_semantics(self):
        """Exactly-Once ì‹œë§¨í‹± ê²€ì¦"""
        print("\n[ê²€ì¦] Exactly-Once Delivery í…ŒìŠ¤íŠ¸...")
        
        topic = 'exactly_once_test'
        
        # Idempotent Producer ì„¤ì •
        producer = KafkaProducer(
            bootstrap_servers=self.bootstrap_servers,
            enable_idempotence=True,  # ì¤‘ìš”: ì¤‘ë³µ ë°©ì§€
            acks='all',
            max_in_flight_requests_per_connection=5,
            retries=10,
            value_serializer=lambda v: json.dumps(v).encode()
        )
        
        # íŠ¸ëœì­ì…˜ IDë¡œ ì¤‘ë³µ ì²´í¬
        sent_ids = set()
        for i in range(1000):
            msg_id = f"msg_{i}_{time.time()}"
            sent_ids.add(msg_id)
            
            producer.send(topic, {
                'id': msg_id,
                'sequence': i,
                'timestamp': time.time()
            })
        
        producer.flush()
        
        # Consumerë¡œ ê²€ì¦
        consumer = KafkaConsumer(
            topic,
            bootstrap_servers=self.bootstrap_servers,
            auto_offset_reset='earliest',
            value_deserializer=lambda m: json.loads(m.decode())
        )
        
        received_ids = []
        start = time.time()
        while time.time() - start < 5:
            msgs = consumer.poll(timeout_ms=1000)
            for tp, records in msgs.items():
                for record in records:
                    received_ids.append(record.value['id'])
        
        # ì¤‘ë³µ ê²€ì‚¬
        duplicates = [x for x in received_ids if received_ids.count(x) > 1]
        if duplicates:
            print(f"  âŒ ì¤‘ë³µ ë°œê²¬: {len(set(duplicates))}ê°œ")
            self.test_results['duplicates'] = duplicates[:10]
        else:
            print(f"  âœ… ì¤‘ë³µ ì—†ìŒ (ì „ì†¡: {len(sent_ids)}, ìˆ˜ì‹ : {len(received_ids)})")
        
        consumer.close()
        return len(duplicates) == 0
    
    def test_message_ordering(self):
        """íŒŒí‹°ì…˜ ë‚´ ë©”ì‹œì§€ ìˆœì„œ ë³´ì¥ ê²€ì¦"""
        print("\n[ê²€ì¦] ë©”ì‹œì§€ ìˆœì„œ ë³´ì¥ í…ŒìŠ¤íŠ¸...")
        
        topic = 'order_test'
        
        producer = KafkaProducer(
            bootstrap_servers=self.bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode(),
            key_serializer=lambda k: k.encode()
        )
        
        # ê°™ì€ í‚¤ë¡œ ì „ì†¡ (ê°™ì€ íŒŒí‹°ì…˜ ë³´ì¥)
        key = 'order_key_1'
        for i in range(100):
            producer.send(topic, key=key, value={
                'sequence': i,
                'timestamp': time.time()
            })
        
        producer.flush()
        
        # ìˆœì„œ ê²€ì¦
        consumer = KafkaConsumer(
            topic,
            bootstrap_servers=self.bootstrap_servers,
            auto_offset_reset='earliest',
            value_deserializer=lambda m: json.loads(m.decode())
        )
        
        sequences = []
        start = time.time()
        while time.time() - start < 3:
            msgs = consumer.poll(timeout_ms=500)
            for tp, records in msgs.items():
                for record in records:
                    if record.key and record.key.decode() == key:
                        sequences.append(record.value['sequence'])
        
        # ìˆœì„œ í™•ì¸
        out_of_order = []
        for i in range(1, len(sequences)):
            if sequences[i] < sequences[i-1]:
                out_of_order.append((sequences[i-1], sequences[i]))
        
        if out_of_order:
            print(f"  âŒ ìˆœì„œ ê¹¨ì§: {len(out_of_order)}ê±´")
            self.test_results['out_of_order'] = out_of_order[:5]
        else:
            print(f"  âœ… ìˆœì„œ ë³´ì¥ë¨ ({len(sequences)}ê°œ ë©”ì‹œì§€)")
        
        consumer.close()
        return len(out_of_order) == 0
    
    def test_partition_distribution(self):
        """íŒŒí‹°ì…˜ ë¶„ì‚° ê· í˜• í…ŒìŠ¤íŠ¸"""
        print("\n[ê²€ì¦] íŒŒí‹°ì…˜ ë¶„ì‚° í…ŒìŠ¤íŠ¸...")
        
        topic = 'partition_test'
        
        producer = KafkaProducer(
            bootstrap_servers=self.bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode()
        )
        
        # ë‹¤ì–‘í•œ í‚¤ë¡œ ì „ì†¡
        partition_count = defaultdict(int)
        
        for i in range(1000):
            key = f"key_{i % 100}"  # 100ê°œì˜ ë‹¤ë¥¸ í‚¤
            
            metadata = producer.send(
                topic,
                key=key.encode(),
                value={'data': f'message_{i}'}
            ).get(timeout=10)
            
            partition_count[metadata.partition] += 1
        
        producer.flush()
        
        # ë¶„ì‚° ë¶„ì„
        total = sum(partition_count.values())
        print(f"  íŒŒí‹°ì…˜ë³„ ë¶„í¬:")
        for partition, count in sorted(partition_count.items()):
            percentage = (count / total) * 100
            print(f"    íŒŒí‹°ì…˜ {partition}: {count}ê°œ ({percentage:.1f}%)")
        
        # í‘œì¤€í¸ì°¨ ê³„ì‚°
        counts = list(partition_count.values())
        if counts:
            std_dev = np.std(counts)
            mean = np.mean(counts)
            cv = (std_dev / mean) * 100 if mean > 0 else 0
            
            print(f"  ë³€ë™ê³„ìˆ˜: {cv:.2f}%")
            
            if cv < 20:
                print(f"  âœ… ê· ë“± ë¶„ì‚° (CV < 20%)")
                return True
            else:
                print(f"  âš ï¸ ë¶ˆê· ë“± ë¶„ì‚° (CV = {cv:.2f}%)")
                return False
        
        return True
    
    def test_consumer_lag(self):
        """Consumer LAG ëª¨ë‹ˆí„°ë§"""
        print("\n[ê²€ì¦] Consumer LAG í…ŒìŠ¤íŠ¸...")
        
        topic = 'lag_test'
        group_id = 'lag_test_group'
        
        # Producerë¡œ ëŒ€ëŸ‰ ë©”ì‹œì§€ ì „ì†¡
        producer = KafkaProducer(
            bootstrap_servers=self.bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode()
        )
        
        print("  ëŒ€ëŸ‰ ë©”ì‹œì§€ ì „ì†¡ ì¤‘...")
        for i in range(5000):
            producer.send(topic, {'seq': i})
        producer.flush()
        
        # Consumer ì‹œì‘ (ëŠë¦¬ê²Œ ì²˜ë¦¬)
        consumer = KafkaConsumer(
            topic,
            bootstrap_servers=self.bootstrap_servers,
            group_id=group_id,
            auto_offset_reset='earliest',
            value_deserializer=lambda m: json.loads(m.decode())
        )
        
        # LAG ì¸¡ì •
        processed = 0
        max_lag = 0
        
        for _ in range(10):  # 10ë²ˆë§Œ í´ë§
            msgs = consumer.poll(timeout_ms=1000, max_records=100)
            
            for tp, records in msgs.items():
                processed += len(records)
                
                # í˜„ì¬ ì˜¤í”„ì…‹ê³¼ ìµœì‹  ì˜¤í”„ì…‹ ë¹„êµ
                committed = consumer.committed(tp) or 0
                highwater = consumer.highwater(tp)
                lag = highwater - committed
                max_lag = max(max_lag, lag)
                
            time.sleep(0.5)  # ì˜ë„ì  ì§€ì—°
        
        print(f"  ì²˜ë¦¬: {processed}ê°œ")
        print(f"  ìµœëŒ€ LAG: {max_lag}")
        
        if max_lag > 1000:
            print(f"  âš ï¸ ë†’ì€ LAG ê°ì§€ (> 1000)")
            self.test_results['latency_issues'].append(f"LAG: {max_lag}")
        else:
            print(f"  âœ… LAG ì •ìƒ ë²”ìœ„")
        
        consumer.close()
        return max_lag < 1000
    
    def test_schema_evolution(self):
        """ìŠ¤í‚¤ë§ˆ ì§„í™” í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸"""
        print("\n[ê²€ì¦] ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸...")
        
        topic = 'schema_test'
        
        producer = KafkaProducer(
            bootstrap_servers=self.bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode()
        )
        
        # V1 ìŠ¤í‚¤ë§ˆ
        v1_messages = [
            {'version': 1, 'id': i, 'name': f'item_{i}'} 
            for i in range(10)
        ]
        
        # V2 ìŠ¤í‚¤ë§ˆ (í•„ë“œ ì¶”ê°€)
        v2_messages = [
            {'version': 2, 'id': i, 'name': f'item_{i}', 'category': 'new'} 
            for i in range(10, 20)
        ]
        
        # V3 ìŠ¤í‚¤ë§ˆ (í•„ë“œ íƒ€ì… ë³€ê²½ ì‹œë„)
        v3_messages = [
            {'version': 3, 'id': str(i), 'name': f'item_{i}', 'category': 'new'} 
            for i in range(20, 30)
        ]
        
        # ì „ì†¡
        for msg in v1_messages + v2_messages + v3_messages:
            producer.send(topic, msg)
        producer.flush()
        
        # ìˆ˜ì‹  ë° ê²€ì¦
        consumer = KafkaConsumer(
            topic,
            bootstrap_servers=self.bootstrap_servers,
            auto_offset_reset='earliest',
            value_deserializer=lambda m: json.loads(m.decode())
        )
        
        schema_issues = []
        messages_by_version = defaultdict(list)
        
        start = time.time()
        while time.time() - start < 3:
            msgs = consumer.poll(timeout_ms=500)
            for tp, records in msgs.items():
                for record in records:
                    msg = record.value
                    version = msg.get('version', 0)
                    messages_by_version[version].append(msg)
                    
                    # ìŠ¤í‚¤ë§ˆ ê²€ì¦
                    if version == 1 and 'category' in msg:
                        schema_issues.append(f"V1ì— ì˜ˆìƒì¹˜ ëª»í•œ í•„ë“œ: category")
                    if version >= 2 and 'category' not in msg:
                        schema_issues.append(f"V{version}ì— í•„ìˆ˜ í•„ë“œ ëˆ„ë½: category")
                    if version == 3 and not isinstance(msg.get('id'), str):
                        schema_issues.append(f"V3 íƒ€ì… ë¶ˆì¼ì¹˜: idëŠ” stringì´ì–´ì•¼ í•¨")
        
        print(f"  ë²„ì „ë³„ ë©”ì‹œì§€ ìˆ˜ì‹ :")
        for v, msgs in sorted(messages_by_version.items()):
            print(f"    V{v}: {len(msgs)}ê°œ")
        
        if schema_issues:
            print(f"  âŒ ìŠ¤í‚¤ë§ˆ ë¬¸ì œ: {len(schema_issues)}ê±´")
            self.test_results['schema_violations'] = schema_issues[:5]
        else:
            print(f"  âœ… ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± ìœ ì§€")
        
        consumer.close()
        return len(schema_issues) == 0
    
    def test_data_completeness(self):
        """ë°ì´í„° ì™„ì „ì„± ê²€ì¦ (NULL, ëˆ„ë½ í•„ë“œ)"""
        print("\n[ê²€ì¦] ë°ì´í„° ì™„ì „ì„± í…ŒìŠ¤íŠ¸...")
        
        topic = 'completeness_test'
        
        producer = KafkaProducer(
            bootstrap_servers=self.bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode()
        )
        
        # ë‹¤ì–‘í•œ í’ˆì§ˆì˜ ë°ì´í„° ì „ì†¡
        test_data = [
            {'id': 1, 'value': 100, 'timestamp': time.time()},  # ì •ìƒ
            {'id': 2, 'value': None, 'timestamp': time.time()},  # NULL ê°’
            {'id': 3, 'timestamp': time.time()},  # í•„ë“œ ëˆ„ë½
            {'id': None, 'value': 100, 'timestamp': time.time()},  # NULL ID
            {},  # ë¹ˆ ê°ì²´
            {'id': 5, 'value': 'invalid', 'timestamp': 'invalid'},  # íƒ€ì… ì˜¤ë¥˜
        ]
        
        for data in test_data:
            producer.send(topic, data)
        producer.flush()
        
        # ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        consumer = KafkaConsumer(
            topic,
            bootstrap_servers=self.bootstrap_servers,
            auto_offset_reset='earliest',
            value_deserializer=lambda m: json.loads(m.decode())
        )
        
        quality_issues = {
            'null_values': 0,
            'missing_fields': 0,
            'type_errors': 0,
            'empty_records': 0
        }
        
        required_fields = ['id', 'value', 'timestamp']
        
        start = time.time()
        while time.time() - start < 3:
            msgs = consumer.poll(timeout_ms=500)
            for tp, records in msgs.items():
                for record in records:
                    msg = record.value
                    
                    # ë¹ˆ ë ˆì½”ë“œ
                    if not msg:
                        quality_issues['empty_records'] += 1
                        continue
                    
                    # í•„ìˆ˜ í•„ë“œ ì²´í¬
                    for field in required_fields:
                        if field not in msg:
                            quality_issues['missing_fields'] += 1
                        elif msg[field] is None:
                            quality_issues['null_values'] += 1
                    
                    # íƒ€ì… ì²´í¬
                    if 'value' in msg and msg['value'] is not None:
                        if not isinstance(msg['value'], (int, float)):
                            quality_issues['type_errors'] += 1
        
        print(f"  ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ:")
        total_issues = 0
        for issue_type, count in quality_issues.items():
            if count > 0:
                print(f"    {issue_type}: {count}ê±´")
                total_issues += count
        
        if total_issues > 0:
            print(f"  âš ï¸ ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ë°œê²¬: ì´ {total_issues}ê±´")
        else:
            print(f"  âœ… ë°ì´í„° ì™„ì „ì„± í™•ì¸")
        
        consumer.close()
        return total_issues == 0
    
    def generate_report(self):
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "="*60)
        print("ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë¦¬í¬íŠ¸")
        print("="*60)
        
        # ì´ìŠˆ ìš”ì•½
        total_issues = sum(len(v) for v in self.test_results.values())
        
        if total_issues == 0:
            print("âœ… ëª¨ë“  ë°ì´í„° í’ˆì§ˆ í…ŒìŠ¤íŠ¸ í†µê³¼!")
        else:
            print(f"âš ï¸ ì´ {total_issues}ê°œ ì´ìŠˆ ë°œê²¬:")
            
            if self.test_results['duplicates']:
                print(f"\n[ì¤‘ë³µ ë°ì´í„°]")
                for dup in self.test_results['duplicates'][:3]:
                    print(f"  - {dup}")
            
            if self.test_results['out_of_order']:
                print(f"\n[ìˆœì„œ ì˜¤ë¥˜]")
                for oo in self.test_results['out_of_order'][:3]:
                    print(f"  - {oo[0]} â†’ {oo[1]}")
            
            if self.test_results['schema_violations']:
                print(f"\n[ìŠ¤í‚¤ë§ˆ ìœ„ë°˜]")
                for sv in self.test_results['schema_violations'][:3]:
                    print(f"  - {sv}")
            
            if self.test_results['latency_issues']:
                print(f"\n[ì§€ì—° ì´ìŠˆ]")
                for li in self.test_results['latency_issues'][:3]:
                    print(f"  - {li}")
        
        # ê¶Œì¥ì‚¬í•­
        print("\n[ê¶Œì¥ì‚¬í•­]")
        if self.test_results['duplicates']:
            print("  â€¢ Idempotent Producer ì„¤ì • í™œì„±í™”")
            print("  â€¢ Exactly-Once ì‹œë§¨í‹± ì ìš©")
        
        if self.test_results['out_of_order']:
            print("  â€¢ ë‹¨ì¼ íŒŒí‹°ì…˜ ì‚¬ìš© ë˜ëŠ” í‚¤ ê¸°ë°˜ íŒŒí‹°ì…”ë‹")
            print("  â€¢ max.in.flight.requests.per.connection=1 ì„¤ì •")
        
        if self.test_results['schema_violations']:
            print("  â€¢ Schema Registry ë„ì… ê²€í† ")
            print("  â€¢ Avro/Protobuf ë“± ìŠ¤í‚¤ë§ˆ ì§„í™” ì§€ì› í¬ë§· ì‚¬ìš©")
        
        if self.test_results['latency_issues']:
            print("  â€¢ Consumer ë³‘ë ¬ ì²˜ë¦¬ ì¦ê°€")
            print("  â€¢ ë°°ì¹˜ í¬ê¸° ë° í´ë§ ê°„ê²© ìµœì í™”")
        
        print("="*60)

def main():
    tester = DataQualityTest('localhost:9092')
    
    # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tests = [
        tester.test_exactly_once_semantics,
        tester.test_message_ordering,
        tester.test_partition_distribution,
        tester.test_consumer_lag,
        tester.test_schema_evolution,
        tester.test_data_completeness
    ]
    
    results = []
    for test in tests:
        try:
            results.append(test())
        except Exception as e:
            print(f"  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            results.append(False)
    
    # ìµœì¢… ë¦¬í¬íŠ¸
    tester.generate_report()
    
    # ì„±ê³µ/ì‹¤íŒ¨ íŒì •
    if all(results):
        print("\nğŸ‰ ë°ì´í„° íŒŒì´í”„ë¼ì¸ í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ!")
        return 0
    else:
        print("\nâŒ ì¼ë¶€ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return 1

if __name__ == "__main__":
    exit(main())