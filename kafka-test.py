#!/usr/bin/env python3

"""
Kafka ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ëª©ì : ë°ì´í„°ê°€ Kafkaì— ì •ìƒì ìœ¼ë¡œ ì €ì¥ë˜ê³  ì†Œë¹„ë˜ëŠ”ì§€ ê²€ì¦
"""

import json
import time
import uuid
import threading
from datetime import datetime
from kafka import KafkaProducer, KafkaConsumer, KafkaAdminClient
from kafka.admin import NewTopic
from kafka.errors import KafkaError
import argparse
import sys

class KafkaDataPipelineTest:
    def __init__(self, bootstrap_servers='localhost:9092'):
        self.bootstrap_servers = bootstrap_servers
        self.test_topic = f'test_topic_{uuid.uuid4().hex[:8]}'
        self.messages_sent = []
        self.messages_received = []
        self.producer = None
        self.consumer = None
        
    def setup(self):
        """Kafka ì—°ê²° ì„¤ì • ë° í† í”½ ìƒì„±"""
        print(f"[ì„¤ì •] Kafka ì„œë²„ ì—°ê²°: {self.bootstrap_servers}")
        
        try:
            # Admin í´ë¼ì´ì–¸íŠ¸ë¡œ í† í”½ ìƒì„±
            admin = KafkaAdminClient(
                bootstrap_servers=self.bootstrap_servers,
                client_id='test_admin'
            )
            
            topic = NewTopic(
                name=self.test_topic,
                num_partitions=3,
                replication_factor=1
            )
            
            admin.create_topics([topic])
            print(f"[ì„¤ì •] í…ŒìŠ¤íŠ¸ í† í”½ ìƒì„±: {self.test_topic}")
            
            # Producer ì„¤ì •
            self.producer = KafkaProducer(
                bootstrap_servers=self.bootstrap_servers,
                value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                acks='all',  # ëª¨ë“  ë ˆí”Œë¦¬ì¹´ í™•ì¸
                retries=3,
                max_in_flight_requests_per_connection=1,
                compression_type='gzip'
            )
            
            # Consumer ì„¤ì •
            self.consumer = KafkaConsumer(
                self.test_topic,
                bootstrap_servers=self.bootstrap_servers,
                value_deserializer=lambda m: json.loads(m.decode('utf-8')),
                auto_offset_reset='earliest',
                enable_auto_commit=True,
                group_id=f'test_group_{uuid.uuid4().hex[:8]}'
            )
            
            print("[ì„¤ì •] Producer/Consumer ì´ˆê¸°í™” ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"[ì˜¤ë¥˜] Kafka ì„¤ì • ì‹¤íŒ¨: {e}")
            return False
    
    def produce_messages(self, count=100, interval=0.01):
        """í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ìƒì„± ë° ì „ì†¡"""
        print(f"\n[Producer] {count}ê°œ ë©”ì‹œì§€ ì „ì†¡ ì‹œì‘...")
        
        success_count = 0
        error_count = 0
        
        for i in range(count):
            message = {
                'id': str(uuid.uuid4()),
                'sequence': i,
                'timestamp': datetime.now().isoformat(),
                'data': {
                    'sensor_id': f'sensor_{i % 10}',
                    'value': 20.0 + (i % 10),
                    'unit': 'celsius'
                },
                'test_run': self.test_topic
            }
            
            try:
                future = self.producer.send(
                    self.test_topic,
                    value=message,
                    key=str(i % 3).encode('utf-8')  # íŒŒí‹°ì…˜ ë¶„ì‚°
                )
                
                # ë™ê¸° ì „ì†¡ í™•ì¸
                record_metadata = future.get(timeout=10)
                
                self.messages_sent.append(message)
                success_count += 1
                
                if (i + 1) % 10 == 0:
                    print(f"  ì „ì†¡ ì§„í–‰: {i + 1}/{count}")
                
                time.sleep(interval)
                
            except KafkaError as e:
                print(f"  [ì˜¤ë¥˜] ë©”ì‹œì§€ {i} ì „ì†¡ ì‹¤íŒ¨: {e}")
                error_count += 1
        
        self.producer.flush()
        print(f"[Producer] ì™„ë£Œ - ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {error_count}")
        return success_count
    
    def consume_messages(self, timeout=30):
        """ë©”ì‹œì§€ ì†Œë¹„ ë° ê²€ì¦"""
        print(f"\n[Consumer] ë©”ì‹œì§€ ìˆ˜ì‹  ì‹œì‘ (ìµœëŒ€ {timeout}ì´ˆ)...")
        
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            msg_pack = self.consumer.poll(timeout_ms=1000)
            
            if not msg_pack:
                continue
                
            for tp, messages in msg_pack.items():
                for message in messages:
                    self.messages_received.append(message.value)
                    
                    if len(self.messages_received) % 10 == 0:
                        print(f"  ìˆ˜ì‹  ì§„í–‰: {len(self.messages_received)}ê°œ")
            
            # ëª¨ë“  ë©”ì‹œì§€ ìˆ˜ì‹  ì™„ë£Œ í™•ì¸
            if len(self.messages_received) >= len(self.messages_sent):
                break
        
        print(f"[Consumer] ì™„ë£Œ - ìˆ˜ì‹ : {len(self.messages_received)}ê°œ")
        return len(self.messages_received)
    
    def verify_data_integrity(self):
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        print(f"\n[ê²€ì¦] ë°ì´í„° ë¬´ê²°ì„± í™•ì¸...")
        
        # 1. ìˆ˜ëŸ‰ í™•ì¸
        sent_count = len(self.messages_sent)
        received_count = len(self.messages_received)
        
        print(f"  ì „ì†¡: {sent_count}, ìˆ˜ì‹ : {received_count}")
        
        if sent_count != received_count:
            print(f"  âš ï¸ ë©”ì‹œì§€ ì†ì‹¤ ê°ì§€: {sent_count - received_count}ê°œ")
            return False
        
        # 2. ìˆœì„œ ë° ë‚´ìš© í™•ì¸
        sent_ids = {msg['id'] for msg in self.messages_sent}
        received_ids = {msg['id'] for msg in self.messages_received}
        
        missing = sent_ids - received_ids
        if missing:
            print(f"  âš ï¸ ëˆ„ë½ëœ ë©”ì‹œì§€ ID: {list(missing)[:5]}...")
            return False
        
        duplicate = [msg['id'] for msg in self.messages_received 
                    if self.messages_received.count(msg) > 1]
        if duplicate:
            print(f"  âš ï¸ ì¤‘ë³µ ë©”ì‹œì§€ ê°ì§€: {len(duplicate)}ê°œ")
            return False
        
        print("  âœ… ë°ì´í„° ë¬´ê²°ì„± í™•ì¸ ì™„ë£Œ")
        return True
    
    def measure_latency(self):
        """ì§€ì—° ì‹œê°„ ì¸¡ì •"""
        print(f"\n[ì„±ëŠ¥] ì§€ì—° ì‹œê°„ ì¸¡ì •...")
        
        latencies = []
        
        for i in range(10):
            start = time.time()
            
            test_msg = {
                'latency_test': i,
                'timestamp': time.time()
            }
            
            future = self.producer.send(self.test_topic, value=test_msg)
            future.get(timeout=10)
            
            end = time.time()
            latency = (end - start) * 1000  # ms
            latencies.append(latency)
        
        avg_latency = sum(latencies) / len(latencies)
        min_latency = min(latencies)
        max_latency = max(latencies)
        
        print(f"  í‰ê· : {avg_latency:.2f}ms")
        print(f"  ìµœì†Œ: {min_latency:.2f}ms")
        print(f"  ìµœëŒ€: {max_latency:.2f}ms")
        
        return avg_latency
    
    def test_throughput(self, duration=10):
        """ì²˜ë¦¬ëŸ‰ í…ŒìŠ¤íŠ¸"""
        print(f"\n[ì„±ëŠ¥] ì²˜ë¦¬ëŸ‰ í…ŒìŠ¤íŠ¸ ({duration}ì´ˆ)...")
        
        count = 0
        start_time = time.time()
        message_size = 1024  # 1KB ë©”ì‹œì§€
        
        dummy_data = 'x' * message_size
        
        while time.time() - start_time < duration:
            try:
                self.producer.send(
                    self.test_topic,
                    value={'data': dummy_data, 'seq': count}
                )
                count += 1
            except Exception as e:
                print(f"  ì˜¤ë¥˜: {e}")
                break
        
        self.producer.flush()
        
        elapsed = time.time() - start_time
        throughput = count / elapsed
        data_rate = (count * message_size) / (1024 * 1024) / elapsed  # MB/s
        
        print(f"  ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰: {throughput:.2f} msgs/sec")
        print(f"  ë°ì´í„° ì²˜ë¦¬ëŸ‰: {data_rate:.2f} MB/s")
        print(f"  ì´ ì „ì†¡: {count}ê°œ ë©”ì‹œì§€")
        
        return throughput
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        print(f"\n[ì •ë¦¬] í…ŒìŠ¤íŠ¸ ë¦¬ì†ŒìŠ¤ ì •ë¦¬...")
        
        if self.producer:
            self.producer.close()
        if self.consumer:
            self.consumer.close()
        
        # í…ŒìŠ¤íŠ¸ í† í”½ ì‚­ì œ
        try:
            admin = KafkaAdminClient(
                bootstrap_servers=self.bootstrap_servers,
                client_id='test_admin_cleanup'
            )
            admin.delete_topics([self.test_topic])
            print(f"  í…ŒìŠ¤íŠ¸ í† í”½ ì‚­ì œ: {self.test_topic}")
        except:
            pass
    
    def run_all_tests(self):
        """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("=" * 60)
        print("Kafka ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 60)
        
        results = {
            'setup': False,
            'produce': 0,
            'consume': 0,
            'integrity': False,
            'latency': 0,
            'throughput': 0
        }
        
        # 1. ì„¤ì •
        if not self.setup():
            print("\n[ì‹¤íŒ¨] Kafka ì—°ê²° ì‹¤íŒ¨")
            return results
        results['setup'] = True
        
        # 2. ë©”ì‹œì§€ ì „ì†¡
        results['produce'] = self.produce_messages(100)
        
        # 3. ë©”ì‹œì§€ ìˆ˜ì‹ 
        results['consume'] = self.consume_messages()
        
        # 4. ë°ì´í„° ë¬´ê²°ì„±
        results['integrity'] = self.verify_data_integrity()
        
        # 5. ì§€ì—° ì‹œê°„
        results['latency'] = self.measure_latency()
        
        # 6. ì²˜ë¦¬ëŸ‰
        results['throughput'] = self.test_throughput(10)
        
        # 7. ì •ë¦¬
        self.cleanup()
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 60)
        print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        print(f"âœ… Kafka ì—°ê²°: {'ì„±ê³µ' if results['setup'] else 'ì‹¤íŒ¨'}")
        print(f"âœ… ë©”ì‹œì§€ ì „ì†¡: {results['produce']}ê°œ")
        print(f"âœ… ë©”ì‹œì§€ ìˆ˜ì‹ : {results['consume']}ê°œ")
        print(f"âœ… ë°ì´í„° ë¬´ê²°ì„±: {'í†µê³¼' if results['integrity'] else 'ì‹¤íŒ¨'}")
        print(f"âœ… í‰ê·  ì§€ì—°ì‹œê°„: {results['latency']:.2f}ms")
        print(f"âœ… ì²˜ë¦¬ëŸ‰: {results['throughput']:.2f} msgs/sec")
        
        # ì „ì²´ í‰ê°€
        if results['setup'] and results['integrity'] and results['produce'] > 0:
            print("\nğŸ‰ ì „ì²´ í…ŒìŠ¤íŠ¸: ì„±ê³µ")
        else:
            print("\nâŒ ì „ì²´ í…ŒìŠ¤íŠ¸: ì‹¤íŒ¨")
        
        return results

def main():
    parser = argparse.ArgumentParser(description='Kafka ë°ì´í„° íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--bootstrap-servers', default='localhost:9092',
                       help='Kafka ë¸Œë¡œì»¤ ì£¼ì†Œ (ê¸°ë³¸: localhost:9092)')
    parser.add_argument('--simple', action='store_true',
                       help='ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰')
    
    args = parser.parse_args()
    
    tester = KafkaDataPipelineTest(args.bootstrap_servers)
    
    if args.simple:
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        if tester.setup():
            print("âœ… Kafka ì—°ê²° ì„±ê³µ!")
            tester.cleanup()
        else:
            print("âŒ Kafka ì—°ê²° ì‹¤íŒ¨!")
    else:
        # ì „ì²´ í…ŒìŠ¤íŠ¸
        tester.run_all_tests()

if __name__ == "__main__":
    main()